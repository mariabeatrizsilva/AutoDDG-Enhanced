{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c823add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from autoddg import AutoDDG\n",
    "from autoddg.utils import get_sample\n",
    "import os\n",
    "from autoddg.related.related import RelatedWorkProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabfa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your existing MODEL_CONFIG\n",
    "# MODEL_CONFIG = {\n",
    "#     \"base_url\": \"https://openrouter.ai/api/v1\",\n",
    "#     \"api_key\": os.getenv(\"OPENROUTER_API_KEY\"), \n",
    "#     # \"model_name\": \"mistralai/mistral-7b-instruct:free\", \n",
    "#     \"model_name\": \"google/gemini-2.0-flash-exp:free\",\n",
    "# }\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"base_url\": \"http://localhost:11434/v1\",  # Changed to Ollama\n",
    "    \"api_key\": \"ollama\",  # Dummy key - Ollama doesn't check it\n",
    "    \"model_name\": \"llama3.2\",  # Just the model name, no prefix\n",
    "}\n",
    "\n",
    "# Create client\n",
    "client = OpenAI(\n",
    "    api_key=MODEL_CONFIG[\"api_key\"],\n",
    "    base_url=MODEL_CONFIG[\"base_url\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7797045",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ddg = AutoDDG(\n",
    "    client=client, \n",
    "    model_name=MODEL_CONFIG[\"model_name\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b21675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"../src/autoddg/related/data/code-15.csv\")\n",
    "sample_df, dataset_sample = get_sample(df, sample_size=100)\n",
    "\n",
    "# Step 1: Profile the dataset\n",
    "basic_profile, structural_profile = auto_ddg.profile_dataframe(df)\n",
    "\n",
    "# Step 2: Analyze semantics\n",
    "semantic_profile = auto_ddg.analyze_semantics(sample_df)\n",
    "\n",
    "# Step 3: Generate topic\n",
    "data_topic = auto_ddg.generate_topic(\"CODE-15%: a large scale annotated dataset of 12-lead ECGs\", None, dataset_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512aa469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Analyze related work\n",
    "related_profile = auto_ddg.analyze_related(\n",
    "    pdf_path=\"../src/autoddg/related/papers/code15.pdf\",\n",
    "    dataset_name=\"CODE-15%: a large scale annotated dataset of 12-lead ECGs\",\n",
    "    max_pages=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16584d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate description WITH related work\n",
    "prompt, description = auto_ddg.describe_dataset(\n",
    "    dataset_sample=dataset_sample,\n",
    "    dataset_profile=basic_profile,\n",
    "    use_profile=True,\n",
    "    semantic_profile=semantic_profile,\n",
    "    use_semantic_profile=True,\n",
    "    data_topic=data_topic,\n",
    "    use_topic=True,\n",
    "    related_profile=related_profile,  # Pass the dict here\n",
    "    use_related_profile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b0a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(related_profile['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9974b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoddg.evaluation import BaseEvaluator\n",
    "\n",
    "class Eval(BaseEvaluator):\n",
    "    \"\"\"\n",
    "    Evaluate descriptions using OpenRouter Mistral models\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        openrouter_api_key: str = \"ollama\",\n",
    "        model_name: str = \"llama3.2\",\n",
    "    ):\n",
    "        client = OpenAI(\n",
    "            api_key=openrouter_api_key, \n",
    "            base_url=\"http://localhost:11434/v1\"\n",
    "        )\n",
    "        super().__init__(client=client, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cac066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline (without related work)\n",
    "prompt_baseline, description_baseline = auto_ddg.describe_dataset(\n",
    "    dataset_sample=dataset_sample,\n",
    "    dataset_profile=basic_profile,\n",
    "    use_profile=True,\n",
    "    semantic_profile=semantic_profile,\n",
    "    use_semantic_profile=True,\n",
    "    data_topic=data_topic,\n",
    "    use_topic=True,\n",
    "    use_related_profile=False  # Turn OFF\n",
    ")\n",
    "\n",
    "# # With related work\n",
    "# prompt_with_related, description_with_related = auto_ddg.describe_dataset(\n",
    "#     dataset_sample=dataset_sample,\n",
    "#     dataset_profile=basic_profile,\n",
    "#     use_profile=True,\n",
    "#     semantic_profile=semantic_profile,\n",
    "#     use_semantic_profile=True,\n",
    "#     data_topic=data_topic,\n",
    "#     use_topic=True,\n",
    "#     related_profile=related_profile,  # Pass the dict\n",
    "#     use_related_profile=True  # Turn ON\n",
    "# )\n",
    "\n",
    "# # Compare\n",
    "# print(\"Baseline:\", description_baseline)\n",
    "# print(\"\\nWith Related Work:\", description_with_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c01f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline:\", description_baseline)\n",
    "# print(\"\\nWith Related Work:\", description_with_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57629ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ecaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ddg.set_evaluator(Eval(openrouter_api_key=\"ollama\"))\n",
    "\n",
    "\n",
    "# Score descriptions\n",
    "augmented_score = auto_ddg.evaluate_description(description)\n",
    "# baseline_score = auto_ddg.evaluate_description(description_baseline)\n",
    "\n",
    "print(\"Score of the general description:\", augmented_score)\n",
    "# print(\"Score of the search-focused description:\", baseline_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe51ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
